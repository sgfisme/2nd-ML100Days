{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Day100_transfer_learning_HW.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uJe9ENCu_7t4","colab_type":"text"},"source":["## 作業\n","礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n","\n","\n","最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n","\n","另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"]},{"cell_type":"code","metadata":{"id":"zcQnmOAPBBZ6","colab_type":"code","outputId":"b4c71b4f-d177-42b0-c98b-28f990055f85","executionInfo":{"status":"ok","timestamp":1576370784158,"user_tz":-480,"elapsed":84336,"user":{"displayName":"蔡鎮宇","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBJxypa8GEDvBCjCi3aF6flw20Uo1dClYzKlxgutQ=s64","userId":"07876316709697051298"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":1,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 145655 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.14-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.14-0ubuntu1~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.14-0ubuntu1~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6rtRH8zCBaO3","colab_type":"code","outputId":"63274936-d5f6-45cf-83c3-e543637c91c0","executionInfo":{"status":"ok","timestamp":1576370801310,"user_tz":-480,"elapsed":10033,"user":{"displayName":"蔡鎮宇","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBJxypa8GEDvBCjCi3aF6flw20Uo1dClYzKlxgutQ=s64","userId":"07876316709697051298"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":93}},"source":["from google.colab import files\n","uploaded = files.upload()\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-85952e85-6e40-46e8-9dca-12cd4e6f9e10\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-85952e85-6e40-46e8-9dca-12cd4e6f9e10\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving resnet_builder.py to resnet_builder.py\n","User uploaded file \"resnet_builder.py\" with length 5409 bytes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y28ZWmPw_7t6","colab_type":"code","colab":{}},"source":["from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from resnet_builder import resnet # 這是從 resnet_builder.py 中直接 import 撰寫好的 resnet 函數\n","from keras import models, layers\n","from keras.optimizers import Adadelta, Adam, RMSprop\n","from keras.utils import to_categorical\n","from keras.layers import Flatten, Dense, GlobalAveragePooling2D, Dropout\n","from keras.applications.resnet50 import ResNet50\n","\n","BATCH_SIZE = 32 # batch 的大小，如果出現 OOM error，請降低這個值\n","NUM_CLASSES = 10 # 類別的數量，Cifar 10 共有 10 個類別\n","EPOCHS = 30 # 訓練整個資料集共 30個循環\n","IMAGE_SIZE = (32, 32) # 影像大小\n","FREEZE_LAYERS = 1 # 凍結網路層數"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"194TWnKm_7t-","colab_type":"code","outputId":"45a719fb-3c5c-4411-db2e-e08d95725aff","executionInfo":{"status":"ok","timestamp":1576376989434,"user_tz":-480,"elapsed":1887,"user":{"displayName":"蔡鎮宇","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBJxypa8GEDvBCjCi3aF6flw20Uo1dClYzKlxgutQ=s64","userId":"07876316709697051298"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# 讀取資料集並作前處理\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","x_train = x_train / 255.\n","x_test = x_test / 255.\n","y_train = to_categorical(y_train, NUM_CLASSES)\n","y_test = to_categorical(y_test, NUM_CLASSES)\n","\n","# 建立 ImageDataGenerator，並指定我們要做資料增強的數值範圍\n","#train_data_generator = ImageDataGenerator(\n","#    rotation_range=40,\n","#    width_shift_range=0.2,\n","#    height_shift_range=0.2,\n","#    shear_range=0.2,\n","#    zoom_range=0.2,\n","#    channel_shift_range=10,\n","#    horizontal_flip=True,\n","#    fill_mode='nearest')\n","\n","#test_data_generator = ImageDataGenerator()\n","\n","#train_data_imgs = train_data_generator.flow(x_train, y_train, batch_size=BATCH_SIZE, shuffle=False)\n","#test_data_imgs = test_data_generator.flow(x_test, y_test, batch_size=BATCH_SIZE, shuffle=False)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JYB9ILfu_7uB","colab_type":"code","outputId":"0151106f-70ec-4d52-b825-2ee35d48daa2","executionInfo":{"status":"ok","timestamp":1576372543220,"user_tz":-480,"elapsed":6222,"user":{"displayName":"蔡鎮宇","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBJxypa8GEDvBCjCi3aF6flw20Uo1dClYzKlxgutQ=s64","userId":"07876316709697051298"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# 建立 ResNet 模型\n","model = resnet(input_shape=(32,32,3), depth=56)\n","model.summary()"],"execution_count":19,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","Model: \"model_4\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_10 (InputLayer)           (None, 32, 32, 3)    0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_10[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_442 (Activation)     (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 32, 32, 16)   272         activation_442[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_443 (Activation)     (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_443[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_444 (Activation)     (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 32, 32, 64)   1088        activation_442[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 32, 32, 64)   1088        activation_444[0][0]             \n","__________________________________________________________________________________________________\n","add_145 (Add)                   (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n","                                                                 conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         add_145[0][0]                    \n","__________________________________________________________________________________________________\n","activation_445 (Activation)     (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 32, 32, 16)   1040        activation_445[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_446 (Activation)     (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_446[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_447 (Activation)     (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 32, 32, 64)   1088        activation_447[0][0]             \n","__________________________________________________________________________________________________\n","add_146 (Add)                   (None, 32, 32, 64)   0           add_145[0][0]                    \n","                                                                 conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         add_146[0][0]                    \n","__________________________________________________________________________________________________\n","activation_448 (Activation)     (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 32, 32, 16)   1040        activation_448[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_449 (Activation)     (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        activation_449[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","activation_450 (Activation)     (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 32, 32, 64)   1088        activation_450[0][0]             \n","__________________________________________________________________________________________________\n","add_147 (Add)                   (None, 32, 32, 64)   0           add_146[0][0]                    \n","                                                                 conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         add_147[0][0]                    \n","__________________________________________________________________________________________________\n","activation_451 (Activation)     (None, 32, 32, 64)   0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 32, 32, 16)   1040        activation_451[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","activation_452 (Activation)     (None, 32, 32, 16)   0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 32, 32, 16)   2320        activation_452[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","activation_453 (Activation)     (None, 32, 32, 16)   0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 32, 32, 64)   1088        activation_453[0][0]             \n","__________________________________________________________________________________________________\n","add_148 (Add)                   (None, 32, 32, 64)   0           add_147[0][0]                    \n","                                                                 conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 32, 32, 64)   256         add_148[0][0]                    \n","__________________________________________________________________________________________________\n","activation_454 (Activation)     (None, 32, 32, 64)   0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 32, 32, 16)   1040        activation_454[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_455 (Activation)     (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 32, 32, 16)   2320        activation_455[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_456 (Activation)     (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 32, 32, 64)   1088        activation_456[0][0]             \n","__________________________________________________________________________________________________\n","add_149 (Add)                   (None, 32, 32, 64)   0           add_148[0][0]                    \n","                                                                 conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 32, 32, 64)   256         add_149[0][0]                    \n","__________________________________________________________________________________________________\n","activation_457 (Activation)     (None, 32, 32, 64)   0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 32, 32, 16)   1040        activation_457[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_458 (Activation)     (None, 32, 32, 16)   0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 32, 32, 16)   2320        activation_458[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_459 (Activation)     (None, 32, 32, 16)   0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 32, 32, 64)   1088        activation_459[0][0]             \n","__________________________________________________________________________________________________\n","add_150 (Add)                   (None, 32, 32, 64)   0           add_149[0][0]                    \n","                                                                 conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 32, 32, 64)   256         add_150[0][0]                    \n","__________________________________________________________________________________________________\n","activation_460 (Activation)     (None, 32, 32, 64)   0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 16, 16, 64)   4160        activation_460[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 16, 16, 64)   256         conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","activation_461 (Activation)     (None, 16, 16, 64)   0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 16, 16, 64)   36928       activation_461[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 16, 16, 64)   256         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_462 (Activation)     (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 16, 16, 128)  8320        add_150[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 16, 16, 128)  8320        activation_462[0][0]             \n","__________________________________________________________________________________________________\n","add_151 (Add)                   (None, 16, 16, 128)  0           conv2d_24[0][0]                  \n","                                                                 conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 16, 16, 128)  512         add_151[0][0]                    \n","__________________________________________________________________________________________________\n","activation_463 (Activation)     (None, 16, 16, 128)  0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 16, 16, 64)   8256        activation_463[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 16, 16, 64)   256         conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","activation_464 (Activation)     (None, 16, 16, 64)   0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 16, 16, 64)   36928       activation_464[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 16, 16, 64)   256         conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","activation_465 (Activation)     (None, 16, 16, 64)   0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 16, 16, 128)  8320        activation_465[0][0]             \n","__________________________________________________________________________________________________\n","add_152 (Add)                   (None, 16, 16, 128)  0           add_151[0][0]                    \n","                                                                 conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 16, 16, 128)  512         add_152[0][0]                    \n","__________________________________________________________________________________________________\n","activation_466 (Activation)     (None, 16, 16, 128)  0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 16, 16, 64)   8256        activation_466[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 16, 16, 64)   256         conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_467 (Activation)     (None, 16, 16, 64)   0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 16, 16, 64)   36928       activation_467[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 16, 16, 64)   256         conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_468 (Activation)     (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 16, 16, 128)  8320        activation_468[0][0]             \n","__________________________________________________________________________________________________\n","add_153 (Add)                   (None, 16, 16, 128)  0           add_152[0][0]                    \n","                                                                 conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 16, 16, 128)  512         add_153[0][0]                    \n","__________________________________________________________________________________________________\n","activation_469 (Activation)     (None, 16, 16, 128)  0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 16, 16, 64)   8256        activation_469[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 16, 16, 64)   256         conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","activation_470 (Activation)     (None, 16, 16, 64)   0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 16, 16, 64)   36928       activation_470[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 16, 16, 64)   256         conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","activation_471 (Activation)     (None, 16, 16, 64)   0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 16, 16, 128)  8320        activation_471[0][0]             \n","__________________________________________________________________________________________________\n","add_154 (Add)                   (None, 16, 16, 128)  0           add_153[0][0]                    \n","                                                                 conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 16, 16, 128)  512         add_154[0][0]                    \n","__________________________________________________________________________________________________\n","activation_472 (Activation)     (None, 16, 16, 128)  0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 16, 16, 64)   8256        activation_472[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 16, 16, 64)   256         conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_473 (Activation)     (None, 16, 16, 64)   0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 16, 16, 64)   36928       activation_473[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 16, 16, 64)   256         conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","activation_474 (Activation)     (None, 16, 16, 64)   0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 16, 16, 128)  8320        activation_474[0][0]             \n","__________________________________________________________________________________________________\n","add_155 (Add)                   (None, 16, 16, 128)  0           add_154[0][0]                    \n","                                                                 conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 16, 16, 128)  512         add_155[0][0]                    \n","__________________________________________________________________________________________________\n","activation_475 (Activation)     (None, 16, 16, 128)  0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 16, 16, 64)   8256        activation_475[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 16, 16, 64)   256         conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_476 (Activation)     (None, 16, 16, 64)   0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 16, 16, 64)   36928       activation_476[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 16, 16, 64)   256         conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","activation_477 (Activation)     (None, 16, 16, 64)   0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 16, 16, 128)  8320        activation_477[0][0]             \n","__________________________________________________________________________________________________\n","add_156 (Add)                   (None, 16, 16, 128)  0           add_155[0][0]                    \n","                                                                 conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 16, 16, 128)  512         add_156[0][0]                    \n","__________________________________________________________________________________________________\n","activation_478 (Activation)     (None, 16, 16, 128)  0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 8, 8, 128)    16512       activation_478[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 8, 8, 128)    512         conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","activation_479 (Activation)     (None, 8, 8, 128)    0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 8, 8, 128)    147584      activation_479[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 8, 8, 128)    512         conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","activation_480 (Activation)     (None, 8, 8, 128)    0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 8, 8, 256)    33024       add_156[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 8, 8, 256)    33024       activation_480[0][0]             \n","__________________________________________________________________________________________________\n","add_157 (Add)                   (None, 8, 8, 256)    0           conv2d_43[0][0]                  \n","                                                                 conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 8, 8, 256)    1024        add_157[0][0]                    \n","__________________________________________________________________________________________________\n","activation_481 (Activation)     (None, 8, 8, 256)    0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 8, 8, 128)    32896       activation_481[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 8, 8, 128)    512         conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","activation_482 (Activation)     (None, 8, 8, 128)    0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 8, 8, 128)    147584      activation_482[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 8, 8, 128)    512         conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_483 (Activation)     (None, 8, 8, 128)    0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 8, 8, 256)    33024       activation_483[0][0]             \n","__________________________________________________________________________________________________\n","add_158 (Add)                   (None, 8, 8, 256)    0           add_157[0][0]                    \n","                                                                 conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 8, 8, 256)    1024        add_158[0][0]                    \n","__________________________________________________________________________________________________\n","activation_484 (Activation)     (None, 8, 8, 256)    0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 8, 8, 128)    32896       activation_484[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 8, 8, 128)    512         conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_485 (Activation)     (None, 8, 8, 128)    0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 8, 8, 128)    147584      activation_485[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 8, 8, 128)    512         conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","activation_486 (Activation)     (None, 8, 8, 128)    0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 8, 8, 256)    33024       activation_486[0][0]             \n","__________________________________________________________________________________________________\n","add_159 (Add)                   (None, 8, 8, 256)    0           add_158[0][0]                    \n","                                                                 conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 8, 8, 256)    1024        add_159[0][0]                    \n","__________________________________________________________________________________________________\n","activation_487 (Activation)     (None, 8, 8, 256)    0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 8, 8, 128)    32896       activation_487[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 8, 8, 128)    512         conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","activation_488 (Activation)     (None, 8, 8, 128)    0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 8, 8, 128)    147584      activation_488[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 8, 8, 128)    512         conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","activation_489 (Activation)     (None, 8, 8, 128)    0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 8, 8, 256)    33024       activation_489[0][0]             \n","__________________________________________________________________________________________________\n","add_160 (Add)                   (None, 8, 8, 256)    0           add_159[0][0]                    \n","                                                                 conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 8, 8, 256)    1024        add_160[0][0]                    \n","__________________________________________________________________________________________________\n","activation_490 (Activation)     (None, 8, 8, 256)    0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 8, 8, 128)    32896       activation_490[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 8, 8, 128)    512         conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","activation_491 (Activation)     (None, 8, 8, 128)    0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 8, 8, 128)    147584      activation_491[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 8, 8, 128)    512         conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","activation_492 (Activation)     (None, 8, 8, 128)    0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, 8, 8, 256)    33024       activation_492[0][0]             \n","__________________________________________________________________________________________________\n","add_161 (Add)                   (None, 8, 8, 256)    0           add_160[0][0]                    \n","                                                                 conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 8, 8, 256)    1024        add_161[0][0]                    \n","__________________________________________________________________________________________________\n","activation_493 (Activation)     (None, 8, 8, 256)    0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, 8, 8, 128)    32896       activation_493[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, 8, 8, 128)    512         conv2d_56[0][0]                  \n","__________________________________________________________________________________________________\n","activation_494 (Activation)     (None, 8, 8, 128)    0           batch_normalization_53[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_57 (Conv2D)              (None, 8, 8, 128)    147584      activation_494[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_54 (BatchNo (None, 8, 8, 128)    512         conv2d_57[0][0]                  \n","__________________________________________________________________________________________________\n","activation_495 (Activation)     (None, 8, 8, 128)    0           batch_normalization_54[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_58 (Conv2D)              (None, 8, 8, 256)    33024       activation_495[0][0]             \n","__________________________________________________________________________________________________\n","add_162 (Add)                   (None, 8, 8, 256)    0           add_161[0][0]                    \n","                                                                 conv2d_58[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_55 (BatchNo (None, 8, 8, 256)    1024        add_162[0][0]                    \n","__________________________________________________________________________________________________\n","activation_496 (Activation)     (None, 8, 8, 256)    0           batch_normalization_55[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d_1 (AveragePoo (None, 1, 1, 256)    0           activation_496[0][0]             \n","__________________________________________________________________________________________________\n","flatten_9 (Flatten)             (None, 256)          0           average_pooling2d_1[0][0]        \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 10)           2570        flatten_9[0][0]                  \n","==================================================================================================\n","Total params: 1,673,738\n","Trainable params: 1,663,338\n","Non-trainable params: 10,400\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yO6WHFVk_7uD","colab_type":"code","outputId":"1c17f9ac-853e-432d-c1df-d0fb0d5a3f05","executionInfo":{"status":"ok","timestamp":1576376354696,"user_tz":-480,"elapsed":3768088,"user":{"displayName":"蔡鎮宇","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBJxypa8GEDvBCjCi3aF6flw20Uo1dClYzKlxgutQ=s64","userId":"07876316709697051298"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#batch_size = 64 # batch 的大小，如果出現 OOM error，請降低這個值\n","#num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n","#epochs = 30 # 訓練整個資料集共 30個循環\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=BATCH_SIZE,\n","                    epochs=EPOCHS,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Train on 50000 samples, validate on 10000 samples\n","Epoch 1/30\n","50000/50000 [==============================] - 153s 3ms/step - loss: 2.2367 - acc: 0.5196 - val_loss: 2.4361 - val_acc: 0.4582\n","Epoch 2/30\n","50000/50000 [==============================] - 126s 3ms/step - loss: 1.5670 - acc: 0.6748 - val_loss: 1.6518 - val_acc: 0.6201\n","Epoch 3/30\n","50000/50000 [==============================] - 125s 3ms/step - loss: 1.2576 - acc: 0.7319 - val_loss: 1.5900 - val_acc: 0.6180\n","Epoch 4/30\n","50000/50000 [==============================] - 127s 3ms/step - loss: 1.0733 - acc: 0.7719 - val_loss: 1.2034 - val_acc: 0.7274\n","Epoch 5/30\n","50000/50000 [==============================] - 125s 2ms/step - loss: 0.9548 - acc: 0.7986 - val_loss: 1.3070 - val_acc: 0.6833\n","Epoch 6/30\n","50000/50000 [==============================] - 125s 2ms/step - loss: 0.8727 - acc: 0.8174 - val_loss: 1.7894 - val_acc: 0.5955\n","Epoch 7/30\n","50000/50000 [==============================] - 126s 3ms/step - loss: 0.8146 - acc: 0.8351 - val_loss: 1.1949 - val_acc: 0.7123\n","Epoch 8/30\n","50000/50000 [==============================] - 125s 2ms/step - loss: 0.7690 - acc: 0.8483 - val_loss: 1.4513 - val_acc: 0.6921\n","Epoch 9/30\n","50000/50000 [==============================] - 124s 2ms/step - loss: 0.7358 - acc: 0.8588 - val_loss: 1.4783 - val_acc: 0.6547\n","Epoch 10/30\n","50000/50000 [==============================] - 124s 2ms/step - loss: 0.7065 - acc: 0.8684 - val_loss: 1.4802 - val_acc: 0.6874\n","Epoch 11/30\n","50000/50000 [==============================] - 125s 2ms/step - loss: 0.6848 - acc: 0.8779 - val_loss: 0.9660 - val_acc: 0.7872\n","Epoch 12/30\n","50000/50000 [==============================] - 125s 2ms/step - loss: 0.6662 - acc: 0.8844 - val_loss: 1.3660 - val_acc: 0.7122\n","Epoch 13/30\n","50000/50000 [==============================] - 125s 2ms/step - loss: 0.6531 - acc: 0.8897 - val_loss: 1.2037 - val_acc: 0.7343\n","Epoch 14/30\n","50000/50000 [==============================] - 125s 2ms/step - loss: 0.6378 - acc: 0.8970 - val_loss: 1.1538 - val_acc: 0.7603\n","Epoch 15/30\n","50000/50000 [==============================] - 125s 2ms/step - loss: 0.6242 - acc: 0.9003 - val_loss: 1.0563 - val_acc: 0.7686\n","Epoch 16/30\n","50000/50000 [==============================] - 124s 2ms/step - loss: 0.6177 - acc: 0.9047 - val_loss: 1.4790 - val_acc: 0.6972\n","Epoch 17/30\n","50000/50000 [==============================] - 123s 2ms/step - loss: 0.6075 - acc: 0.9085 - val_loss: 1.1921 - val_acc: 0.7771\n","Epoch 18/30\n","50000/50000 [==============================] - 124s 2ms/step - loss: 0.5989 - acc: 0.9126 - val_loss: 1.5429 - val_acc: 0.7109\n","Epoch 19/30\n","50000/50000 [==============================] - 123s 2ms/step - loss: 0.5935 - acc: 0.9153 - val_loss: 1.2298 - val_acc: 0.7590\n","Epoch 20/30\n","50000/50000 [==============================] - 123s 2ms/step - loss: 0.5858 - acc: 0.9186 - val_loss: 1.4532 - val_acc: 0.7350\n","Epoch 21/30\n","50000/50000 [==============================] - 124s 2ms/step - loss: 0.5796 - acc: 0.9212 - val_loss: 1.2633 - val_acc: 0.7560\n","Epoch 22/30\n","50000/50000 [==============================] - 124s 2ms/step - loss: 0.5790 - acc: 0.9225 - val_loss: 1.0398 - val_acc: 0.8033\n","Epoch 23/30\n","50000/50000 [==============================] - 124s 2ms/step - loss: 0.5712 - acc: 0.9247 - val_loss: 1.6321 - val_acc: 0.7121\n","Epoch 24/30\n","50000/50000 [==============================] - 124s 2ms/step - loss: 0.5620 - acc: 0.9281 - val_loss: 1.1710 - val_acc: 0.7817\n","Epoch 25/30\n","50000/50000 [==============================] - 124s 2ms/step - loss: 0.5620 - acc: 0.9281 - val_loss: 1.5555 - val_acc: 0.7209\n","Epoch 26/30\n","50000/50000 [==============================] - 124s 2ms/step - loss: 0.5577 - acc: 0.9298 - val_loss: 1.2177 - val_acc: 0.7594\n","Epoch 27/30\n","50000/50000 [==============================] - 123s 2ms/step - loss: 0.5594 - acc: 0.9306 - val_loss: 1.5492 - val_acc: 0.7382\n","Epoch 28/30\n","50000/50000 [==============================] - 123s 2ms/step - loss: 0.5538 - acc: 0.9319 - val_loss: 1.2164 - val_acc: 0.7631\n","Epoch 29/30\n","50000/50000 [==============================] - 123s 2ms/step - loss: 0.5468 - acc: 0.9337 - val_loss: 1.8443 - val_acc: 0.7033\n","Epoch 30/30\n","50000/50000 [==============================] - 123s 2ms/step - loss: 0.5446 - acc: 0.9353 - val_loss: 1.2071 - val_acc: 0.7660\n","Test loss: 1.2070833396911622\n","Test accuracy: 0.766\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TD4ABXhs_7uF","colab_type":"code","outputId":"256e189a-b8a4-4237-a558-6dfc2f676dc9","executionInfo":{"status":"ok","timestamp":1576377298714,"user_tz":-480,"elapsed":23026,"user":{"displayName":"蔡鎮宇","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBJxypa8GEDvBCjCi3aF6flw20Uo1dClYzKlxgutQ=s64","userId":"07876316709697051298"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["# 以訓練好的 ResNet50 為基礎來建立模型，\n","# 捨棄 ResNet50 頂層的 fully connected layers\n","conv_base = ResNet50(include_top=False, weights='imagenet', \n","               input_shape=(200, 200, 3))\n","\n","model = models.Sequential()\n","model.add(layers.UpSampling2D((2,2)))\n","model.add(layers.UpSampling2D((2,2)))\n","model.add(layers.UpSampling2D((2,2)))\n","model.add(conv_base)\n","model.add(layers.Flatten())\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n","\n","# 增加 DropOut layer\n","#x = Dropout(0.5)(x)\n","\n","# 增加 Dense layer，以 softmax 產生個類別的機率值\n","#output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n","\n","#net_final = Model(inputs=model.input, outputs=output_layer)\n","\n","# 設定凍結與要進行訓練的網路層\n","#for layer in net_final.layers[:FREEZE_LAYERS]:\n","#    layer.trainable = False\n","#for layer in net_final.layers[FREEZE_LAYERS:]:\n","#    layer.trainable = True\n","\n","# 使用 Adam optimizer，以較低的 learning rate 進行 fine-tuning\n","#net_final.compile(optimizer=Adam(lr=1e-5),\n","#                  loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","#net_final.summary()# 以訓練好的 ResNet50 為基礎來建立模型，\n","# 捨棄 ResNet50 頂層的 fully connected layers\n","#model = ResNet50(include_top=False, weights='imagenet', input_tensor=None,\n","#               input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n","\n","#x = model.output\n","#x = Flatten()(x)\n","\n","# 增加 DropOut layer\n","#x = Dropout(0.5)(x)\n","\n","# 增加 Dense layer，以 softmax 產生個類別的機率值\n","#output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n","\n","#net_final = Model(inputs=model.input, outputs=output_layer)\n","\n","# 設定凍結與要進行訓練的網路層\n","#for layer in net_final.layers[:FREEZE_LAYERS]:\n","#    layer.trainable = False\n","#for layer in net_final.layers[FREEZE_LAYERS:]:\n","#    layer.trainable = True\n","\n","# 使用 Adam optimizer，以較低的 learning rate 進行 fine-tuning\n","#net_final.compile(optimizer=Adam(lr=1e-5),\n","#                  loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":28,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n","  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"UcggpY_INwt0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"cdf25baf-81f6-412b-83c1-5b9fcdc866a5","executionInfo":{"status":"ok","timestamp":1576390999256,"user_tz":-480,"elapsed":13626003,"user":{"displayName":"蔡鎮宇","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBJxypa8GEDvBCjCi3aF6flw20Uo1dClYzKlxgutQ=s64","userId":"07876316709697051298"}}},"source":["#model.compile(loss='categorical_crossentropy',\n","#              optimizer=Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0),\n","#              metrics=['accuracy'])\n","\n","model.compile(optimizer=RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['acc'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=BATCH_SIZE,\n","                    epochs=EPOCHS,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":30,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/30\n","50000/50000 [==============================] - 480s 10ms/step - loss: 0.2300 - acc: 0.9179 - val_loss: 0.1121 - val_acc: 0.9598\n","Epoch 2/30\n","50000/50000 [==============================] - 453s 9ms/step - loss: 0.1380 - acc: 0.9506 - val_loss: 0.0700 - val_acc: 0.9779\n","Epoch 3/30\n","50000/50000 [==============================] - 453s 9ms/step - loss: 0.0990 - acc: 0.9671 - val_loss: 0.0495 - val_acc: 0.9852\n","Epoch 4/30\n","50000/50000 [==============================] - 453s 9ms/step - loss: 0.0757 - acc: 0.9766 - val_loss: 0.0429 - val_acc: 0.9867\n","Epoch 5/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0585 - acc: 0.9836 - val_loss: 0.0373 - val_acc: 0.9882\n","Epoch 6/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0455 - acc: 0.9881 - val_loss: 0.0365 - val_acc: 0.9883\n","Epoch 7/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0366 - acc: 0.9911 - val_loss: 0.0336 - val_acc: 0.9896\n","Epoch 8/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0295 - acc: 0.9932 - val_loss: 0.0354 - val_acc: 0.9887\n","Epoch 9/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0252 - acc: 0.9944 - val_loss: 0.0361 - val_acc: 0.9891\n","Epoch 10/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0213 - acc: 0.9955 - val_loss: 0.0358 - val_acc: 0.9895\n","Epoch 11/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0184 - acc: 0.9961 - val_loss: 0.0374 - val_acc: 0.9890\n","Epoch 12/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0170 - acc: 0.9965 - val_loss: 0.0396 - val_acc: 0.9892\n","Epoch 13/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0152 - acc: 0.9969 - val_loss: 0.0394 - val_acc: 0.9897\n","Epoch 14/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0136 - acc: 0.9972 - val_loss: 0.0416 - val_acc: 0.9891\n","Epoch 15/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0128 - acc: 0.9974 - val_loss: 0.0416 - val_acc: 0.9897\n","Epoch 16/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0119 - acc: 0.9976 - val_loss: 0.0457 - val_acc: 0.9892\n","Epoch 17/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0108 - acc: 0.9978 - val_loss: 0.0440 - val_acc: 0.9894\n","Epoch 18/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0103 - acc: 0.9979 - val_loss: 0.0448 - val_acc: 0.9893\n","Epoch 19/30\n","50000/50000 [==============================] - 451s 9ms/step - loss: 0.0098 - acc: 0.9979 - val_loss: 0.0466 - val_acc: 0.9895\n","Epoch 20/30\n","50000/50000 [==============================] - 451s 9ms/step - loss: 0.0094 - acc: 0.9980 - val_loss: 0.0488 - val_acc: 0.9888\n","Epoch 21/30\n","50000/50000 [==============================] - 451s 9ms/step - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0494 - val_acc: 0.9894\n","Epoch 22/30\n","50000/50000 [==============================] - 451s 9ms/step - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0484 - val_acc: 0.9893\n","Epoch 23/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0520 - val_acc: 0.9886\n","Epoch 24/30\n","50000/50000 [==============================] - 453s 9ms/step - loss: 0.0083 - acc: 0.9982 - val_loss: 0.0489 - val_acc: 0.9895\n","Epoch 25/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0494 - val_acc: 0.9895\n","Epoch 26/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0077 - acc: 0.9984 - val_loss: 0.0521 - val_acc: 0.9889\n","Epoch 27/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0067 - acc: 0.9986 - val_loss: 0.0545 - val_acc: 0.9894\n","Epoch 28/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0070 - acc: 0.9984 - val_loss: 0.0551 - val_acc: 0.9894\n","Epoch 29/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.0568 - val_acc: 0.9893\n","Epoch 30/30\n","50000/50000 [==============================] - 452s 9ms/step - loss: 0.0067 - acc: 0.9985 - val_loss: 0.0549 - val_acc: 0.9893\n","Test loss: 0.054860254991374674\n","Test accuracy: 0.9893300025939942\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S3LQUpAQaDKG","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]}]}